[
["branching-processes.html", "Chapter 8 Branching Processes 8.1 Outline 8.2 Motivation 8.3 Simulated examples and the questions they raise 8.4 What is a (Bienaym'e-)Galton-Watson branching process? 8.5 Simulations 8.6 “Extinction” vs “breakout” 8.7 Good and bad set-ups for branching process", " Chapter 8 Branching Processes 8.1 Outline The Galton-Watson-Bienaym'e Process A viral example, simulating a branching process, our questionsThe distribution of the 2nd generation Moment generating functions Extinction probabilities The distribution of offspring of all generations A tractable offspring distribution 8.2 Motivation Until now, we’ve focused on the hidden structures of heterogeneity. Now, we’re switching gears: Stochastic not deterministic In small populations, randomness matters. (Even when risks are homogeneous.) branching processes (“parents producing children”), next Fisher-Wright (“children choosing parents”), and then historical reconstruction from contemporary diversity (“coalescent”). 8.2.1 Very brief history of Branching Processes Bienayme’s lost notes Galton and Watson’s (extinction of families) old motivation: to see if elites were dying out because of “degeneration” Genetics (survival of a mutant) contemporary motivation: evolution and neutral genetic change. what is the chance that a mutant will survive? The bomb (chain reactions) war-time motivation: to see how to build the bomb Anywhere “incipient dynamics” matter. sociological: will all of S. Korea be “Kim”? can we get variance of repro success from name disn? it will give us a headstart on other (less realistic but easier) “drift” models. 8.2.2 Applicability to the Coronavirus? Yes and no. Perhaps the beginning, with first few cases. But once scale gets large, we’ll see that deterministic dynamics take over. One lesson: beyond \\(R_0\\). 8.3 Simulated examples and the questions they raise 8.3.1 Our viral example Here are the chances that the first carrier passes on the virus to \\(k\\) people? \\(k\\) \\(p_k\\) digits 0 .3 0-2 1 .4 3-5 2 .3 6-9 What is \\(R_0\\), (aka \\(m\\))? Calculate. Let’s diagram one chance outcome, using my number “(xxx) xxx-9056” \\(k\\) \\(p_k\\) digits 0 .3 0-2 1 .4 3-5 2 .3 6-9 8.4 What is a (Bienaym'e-)Galton-Watson branching process? \\(p_k\\): Each individual in each generation reproduces independently, following same offspring distribution, with \\(p_k\\) as the probability of having \\(k\\) offspring. \\(Z_n\\): The si\\(Z\\)e of the \\(n\\)’th generation \\(Z_n\\). (\\(Z_1 \\equiv 1\\)) \\(p_0 &gt; 0\\): Some non-zero probability of no children. Variance: None of the \\(p_k\\) are 1 Some questions Galton’s original question What is the chance \\(d\\) of eventual extinction (no “outbreak”)? Or, what is the distribution of surviving family sizes? What are the aggregate properties of many branching processes? (Mean growth, variance, time-paths, eventual size)? 8.5 Simulations k = 0:2 p0 = .3; p1 = .3; p2 = .4; p_k = c(p0, p1, p2) Z1 = 1 set.seed(9) (kids.of.Z1 = sample(x = k, size = Z1, replace = T, prob = p_k)) ## [1] 2 (Z2 = sum(kids.of.Z1)) ## [1] 2 (kids.of.Z2 = sample(x = k, size = Z2, replace = T, prob = p_k)) ## [1] 2 2 (Z3 = sum(kids.of.Z2)) ## [1] 4 (kids.of.Z3 = sample(x = k, size = Z3, replace = T, prob = p_k)) ## [1] 2 1 2 2 (Z4 = sum(kids.of.Z3)) ## [1] 7 Let’s draw the tree. / // // / #A function branch &lt;- function(n_max = 30, pk = c(p0, p1, p2), Z1 = 1) { Z.vec &lt;- rep(NA, n_max) Z.vec[1] &lt;- Z1 for (i in 1:(n_max-1)) { Z.vec[i+1] &lt;- sum(sample(x = k, size = Z.vec[i], replace = T, prob = p_k)) } return(Z.vec) } set.seed(19); branch() ## [1] 1 2 2 4 5 2 2 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 set.seed(99); branch() ## [1] 1 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Let’s see what happens with 20 trials (up to 30 generations) n_trials = 20; n_gen = 30 Z.mat &lt;- matrix(NA, n_trials, n_gen) set.seed(131) for (i in 1:n_trials) Z.mat[i,] &lt;- branch(n_max = n_gen) matplot(t(Z.mat), type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;) How many survive (out of 20)? log-scale suppressWarnings(matplot(t(Z.mat), log = &quot;y&quot;, type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;)) surviving = ifelse(Z.mat[,n_gen] == 0, &quot;extinct&quot;, &quot;survive&quot;) foo &lt;- prop.table(table(surviving)) print( prop.table(table(surviving)) ) ## surviving ## extinct survive ## 0.5 0.5 How would you discribe the time path of the surviving lines? Long term n_trials = 20; n_gen = 100 Z.mat &lt;- matrix(NA, n_trials, n_gen) set.seed(131) for (i in 1:n_trials) Z.mat[i,] &lt;- branch(n_max = n_gen) suppressWarnings(matplot(t(Z.mat), log = &quot;y&quot;, type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;)) What does this remind you of? (Hint: “Leslie”). (See Harris figure) 8.6 “Extinction” vs “breakout” We see that in a super-critical (\\(m &gt; 1\\)) branching process, if a line can survive a few generations and reach a large enough size, it will grow exponentially. What happens if \\(m &lt; 1\\), if \\(m = 1\\)? Discuss. 8.6.1 The Probability Generating Function: Our mathematical tool \\[ h(z) = p_0 + p_1 z + p_2 z^2 + \\ldots \\] The PGF “keeps book” on the probabilities. The chance of \\(k\\) is the coefficient on \\(z^k\\). -$h(0) = $ -$h(1) = $ -$h’(1) = $ The story of two brothers A father has two sons. The probability generating function of their children combined is: \\[ [h(z)]^2 = (p_0 + p_1 z + p_2 z^2) \\times (p_0 + p_1 z + p_2 z^2) \\] Multiply out, and tell me the coefficients on $z^0, z^1, $. What is the probability generating function for the distribution of grandsons? A man has two sons, with probability \\(p_2\\), so PGF in that case is $ p_2 [h(z)]^2 $. But let’s sum over all possible numbers of sons. \\[ p_0 + p_1 h(z) + p_2 [h(z)]^2 + p_3 [h(z)]^3 + \\ldots \\] Which is? (Hint: write a new argument for PGF) \\[ h(h(z)) \\] Can show PGF for the n’th generation is \\[ h(h(h ... \\mbox{$n$ times} h(z))) = h_n(z) \\] exercise: write out \\(h_2(z) = h(h(z))\\) for \\[ h(z) = p_0 + p_1 z + p_2 z^2. \\]} Extinction -“Extinction is forever.”: So, the probability \\(d_n\\) of extinction {} generation \\(n\\) can never decline over time. (Must it always rise?) Recursive extinction -Is non-extinction “forever”?: If \\(\\lim_{n \\rightarrow \\infty} = d(\\infty) &lt; 1\\), then this says there’s a chance \\(1 - d(\\infty)\\) of eternal persistence. We’ll try to figure out more about what this means. If the probability of a female line going extinct in \\(n\\) generations is \\(d_n\\), then this is equivalent to her daughter(s) line(s) going extinct in \\(n-1\\) generations. With \\(p_k\\) chance of having \\(k\\) daughters, we have \\[ d_n = p_0 + p_1 d_{n-1} + \\mbox{What is next term in series?} \\] What can we do with \\[ d_n = h(d_{n-1})? \\] Well, remember that \\(d_n\\) is non-decreasing, and that it’s maximum can be no greater than \\(1.0\\). When \\(d_n\\) reaches it’s limit, say \\(d\\), we won’t need generational subscripts, \\(d\\) will be constant, and will obey \\[ d = h(d) \\] Thus, an amazing result: the probability of ultimate extinction is when the argument equals the PGF of the argument. Can \\(d = 1\\), can \\(d &lt; 1\\) Try \\(d = 1\\). What happens? If we were to find a solution less than 1.0, how would we interpret that? Three cases par(mfrow = c(1,3), pty = &quot;s&quot;) z = seq(0, 1.6, .01) pk = c(.3, .0, .7); names(pk) &lt;- 0:2 d &lt;- pk[&quot;0&quot;] for (i in 1:10) { d &lt;- pk[&quot;0&quot;] + pk[&quot;1&quot;]*d + pk[&quot;2&quot;]*d^2 } ## super-critical hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun &lt;- function(z, hz) { plot(z, hz, type = &quot;l&quot;, ylim = c(0,1.6), ylab = &quot;h(z)&quot;, yaxs = &quot;i&quot;, xaxs = &quot;i&quot;, axes = F) axis(1, at = seq(0, 1.5, .5)) axis(2, at = seq(0, 1.5, .5)) abline(0,1, col = &quot;grey&quot;) lines(z, hz) axis(2, at = pk[&quot;0&quot;], labels = &quot;p0&quot;, col.axis = &quot;red&quot;, col = &quot;red&quot;, lwd = 1, las = 2) } plot.fun(z,hz) points(c(d, 1),c(d, 1)) title(&quot;Super-critical (m &gt; 1) \\n 2 roots&quot;) ## sub-critical pk = c(.3, .55, .15); names(pk) &lt;- 0:2 hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z,hz) title(&quot;Sub-critical (m &lt; 1) \\n 1 root&quot;) points(1,1) ## critical pk = c(.3, .4, .3); names(pk) &lt;- 0:2 hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z, hz) title(&quot;Critical (m = 1), \\n 1 root&quot;) points(1,1) We can prove by answering: What is \\(h&#39;(1)\\)? What is \\(h(0)\\)? Is \\(h&#39;&#39;(z) &gt; 0\\)? pk = c(.3, .0, .7); names(pk) &lt;- 0:2 z = seq(0, 1.6, .01) hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z,hz) Where is \\(h(p_0)\\), \\(h(h(p_0))\\), \\(h(h(h(p_0)))\\), \\(\\ldots\\)? So how do we actually get \\(d\\)? Take the case where \\(p_0 = .3\\), \\(p_1 = 0\\), and \\(p_3 = .7\\) (the one I just plotted). Can do some algebra Or we can recursively iterate on the computer. Numerical recursion pk = c(.3, .0, .7); names(pk) &lt;- 0:2 ## our example d &lt;- pk[&quot;0&quot;] # initial value for (i in 1:20) { d &lt;- pk[&quot;0&quot;] + pk[&quot;1&quot;]*d + pk[&quot;2&quot;]*d^2 if (i %in% c(1,2,19,20)) print(paste(i, d)) } ## [1] &quot;1 0.363&quot; ## [1] &quot;2 0.3922383&quot; ## [1] &quot;19 0.428565882081349&quot; ## [1] &quot;20 0.428568100698915&quot; Did we get the right value? pk = c(.3, .0, .7); names(pk) &lt;- 0:2 z = seq(0, 1.6, .01) hz = pk[&quot;0&quot;] + pk[&quot;1&quot;]*z + pk[&quot;2&quot;]*z^2 plot.fun(z,hz) abline(h = d, col = &quot;green&quot;) abline(v = d, col = &quot;green&quot;) Extinction and non-extinction revisited If \\(m &gt; 1\\), there exists \\(d\\) bigger than 0 and less than unity. This means there’s some positive chance of extinction. But also some chance of never-extinction. (What form does never-extinction take?) suppressWarnings(matplot(t(Z.mat), log = &quot;y&quot;, type = &quot;l&quot;, lty = 1, ylab = &quot;Zn&quot;, xlab = &quot;n&quot;)) Relevance to Corona virus? 8.7 Good and bad set-ups for branching process .column-left{ float: left; width: 50%; text-align: left; } .column-right{ float: right; width: 50%; text-align: left; } Good Unrestricted growth (frontier, new disease, start of a reaction) A “null” model for understanding how apparent structure is just random outcomes. Families that die out didn’t have to have low \\(NRR\\). Just because most new viruses don’t break out, doesn’t mean they aren’t potentially dangerous (\\(R_0 &gt;&gt; 1.0\\)). A model that corresponds our mental model of running a generative process forward. (cf. Fisher-Wright) Bad When offspring of 1 depends on offspring of other (e.g., brothers inheriting a farm) When resource constraints slow growth rates (e.g., Malthus: fertility of next gen depends on fertility of last; SIR model in disease spread) Analysis. PGF is powerful but still we often have to deal with listing all possibilities. Big populations – law of large numbers means randomness doesn’t matter. \\begin{frame}fragile{Our set-up (note: code is revised slightly)} &lt;&lt;echo = T, size = “small”&gt;&gt;= branch &lt;- function(n_max = 30, p_k = c(p0, p1, p2), Z1 = 1) { ## note: this returns 0s when extinct k &lt;- 0:(length(p_k)-1) Z.vec &lt;- rep(NA, n_max) Z.vec[1] &lt;- Z1 for (i in 1:(n_max-1)) { Z.vec[i+1] &lt;- sum(sample(x = k, size = Z.vec[i], replace = T, prob = p_k)) } return(Z.vec) } p0 = .3; p1 = .4; p2 = .3 ## what is m? @ \\end{frame} \\begin{frame}fragile{1000 trials, code} &lt;&lt;echo = T, eval = F&gt;&gt;= n_trials = 1000; n_gen = 100 Z.mat &lt;- matrix(NA, n_trials, n_gen) set.seed(131) for (i in 1:n_trials) Z.mat[i,] &lt;- branch(n_max = n_gen) matplot(t(Z.mat), type = “l”, lty = 1, ylab = “Zn”, xlab = “n”) @ \\end{frame} \\begin{frame}fragile{1000 trials, picture} &lt;&lt;echo = F, eval = T, fig.height = 5&gt;&gt;= n_trials = 1000; n_gen = 100 Z.mat &lt;- matrix(NA, n_trials, n_gen) set.seed(131) for (i in 1:n_trials) Z.mat[i,] &lt;- branch(n_max = n_gen) matplot(t(Z.mat), type = “l”, lty = 1, ylab = “Zn”, xlab = “n”) @ \\end{frame} \\begin{frame}fragile{1000 trials, means} &lt;&lt;echo = T, eval = F&gt;&gt;= Zn_bar = apply(Z.mat, 2, mean) n &lt;- 1:ncol(Z.mat) proportion.zero &lt;- function(x){prop.table(table(x == 0))[“TRUE”]} d_n = apply(Z.mat, 2, proportion.zero) Z.mat.na &lt;- Z.mat; Z.mat.na[Z.mat == 0] &lt;- NA Zn_surv_bar = apply(Z.mat.na, 2, mean, na.rm = T) par(mfrow = c(1,3)) plot(n, Zn_bar, main = “Mean Zn”) plot(n, d_n, main = “Fraction extinct”) plot(n, Zn_surv_bar) ## insert code here for Zn_surv_bar.hat and add a line @ \\end{frame} \\begin{frame}fragile{1000 trials, means, picture} &lt;&lt;echo = F, eval = T, fig.height = 5&gt;&gt;= Zn_bar = apply(Z.mat, 2, mean) n &lt;- 1:ncol(Z.mat) proportion.zero &lt;- function(x){prop.table(table(x == 0))[“TRUE”]} d_n = apply(Z.mat, 2, proportion.zero) Z.mat.na &lt;- Z.mat; Z.mat.na[Z.mat == 0] &lt;- NA Zn_surv_bar = apply(Z.mat.na, 2, mean, na.rm = T) par(mfrow = c(1,3)) plot(n, Zn_bar, main = “Mean Zn”) plot(n, d_n, main = “Fraction extinct”) plot(n, Zn_surv_bar) ## insert code here for Zn_surv_bar.hat and add a line @ \\end{frame} \\begin{frame}fragile{Variance in our simulation} &lt;&lt;fig.height = 5&gt;&gt;= var_Zn = apply(Z.mat, 2, var) n &lt;- 1:ncol(Z.mat) plot(n, var_Zn) @ \\end{frame} % \\begin{frame}fragile{Distribution of \\(Z_n\\)} % &lt;&lt;fig.height = 5&gt;&gt;= % Z20 &lt;- table(table(Z.mat[,20])) % Z5 &lt;- table(table(Z.mat[,5])) % par(mfrow = c(2,2)) % plot(Z20[Z20 &lt; 100]) % plot(log(Z20[Z20 &lt; 100])) % plot(Z5[Z5 &lt; 100]) % plot(log(Z5[Z5 &lt; 100])) % @ % \\end{frame} \\begin{frame}fragile{A picture, Lotka’s parameters for 1920} &lt;&lt;fig.height = 4&gt;&gt;= b = 0.2126 ; c = 0.5893 kk = 1:10 ; p_kk = b * c^(kk-1) p0 = b/(1-c) k = c(0, kk) ; p_k = c(p0, p_kk) plot(k, p_k) @ \\end{frame} \\begin{frame}fragile{A plot of Keyfitz’s numbers for generations 1, 2, and 3. Is it exponential for \\(k &gt; 0\\)?} &lt;&lt;eval = F, echo = T, size = “tiny”&gt;&gt;= ## b = 0.2126 ; c = 0.5893 ## lotka b = 0.3666; c = .5533 ## Keyfitz (from GS) m = b / (1-c)^2 ## [1] 1.260416 d = (1 - b - c) / (c * (1-c)) #[1] 0.8185088 par(mfrow = c(1,1)) for (i in 1:3) { n = i p0_n = d * (m^n - 1)/ (m^n -d) j = kk pj_n = m^n ((1-d) / (m^n - d))^2 ((m^n - 1)/(m^n - d))^(j-1) pk_n &lt;- c(p0_n, pj_n) if (i == 1) plot(k, pk_n, type = “l”, log = &quot;&quot;) if (i &gt; 1) lines(k, pk_n, col = i) } @ \\end{frame} \\begin{frame}fragile{log scale} &lt;&lt;eval = T, echo = F, fig.height = 5&gt;&gt;= ## b = 0.2126 ; c = 0.5893 ## lotka b = 0.3666; c = .5533 ## Keyfitz (from G&amp;S) m = b / (1-c)^2 ## [1] 1.260416 d = (1 - b - c) / (c * (1-c)) #[1] 0.8185088 par(mfrow = c(1,1)) for (i in 1:3) { n = i print(n) p0_n = d * (m^n - 1)/ (m^n -d) j = kk pj_n = m^n * ((1-d) / (m^n - d))^2 * ((m^n - 1)/(m^n - d))^(j-1) pk_n &lt;- c(p0_n, pj_n) if (i == 1) plot(k, pk_n, type = “l”, log = “y”) if (i &gt; 1) lines(k, pk_n, col = i) } @ \\end{frame} % % \\begin{frame}{Let’s switch to R} % Our goal will be to see if distributions look geometric, or not. % \\end{frame} \\end{document} "]
]
